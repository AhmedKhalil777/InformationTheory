{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# بسم الله الرحمن الرحيم"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture - 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue - Linear Algebra Using Python Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget the imports - every session\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "# Quick way to create arrays - Interesting :)\n",
    "x = np.array(range(9))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "# Don't forget to assign the output of the operation\n",
    "x = x.reshape(3,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 3 6]\n",
      " [1 4 7]\n",
      " [2 5 8]]\n"
     ]
    }
   ],
   "source": [
    "#Matrix Transpose\n",
    "# Columns are flipped over the diagonal\n",
    "xT = x.T\n",
    "print(x.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "# Taking the Transpose of the Transpose will give us back the original array\n",
    "print(xT.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Tensors\n",
    "A = np.array((3,3,3,3,3,3,3,3,3,3))\n",
    "print(A.shape)\n",
    "print(len(A.shape))\n",
    "print(A.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagonal Matrices\n",
    "- Matrix is diagonal if $D_{i,j} = 0  \\;\\forall\\; i \\neq j$\n",
    "- $\\begin{bmatrix} 1 & 0 & 0\\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{bmatrix}$\n",
    "- Multiplying by diagonal matrix is computationally efficient\n",
    "- For **diag(v)x**, we need to scale each $x_{i}$ by $v_{i}$, where $v_{i}$ is the diagonal element\n",
    "- Some algorithms restrict their input parameter to be diagonal matrices, for efficiency\n",
    "- Diagonal matrices don't need to be square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "# Diagonal Matrices\n",
    "# Generate the matrix in the same previous manner\n",
    "x = np.arange(9).reshape((3,3))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diagonal Matrices - Continue\n",
    "# Get the diagonal items values\n",
    "np.diag(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 4 0]\n",
      " [0 0 8]]\n"
     ]
    }
   ],
   "source": [
    "# Diagonal Matrices - Continue\n",
    "# Generate the Diagonal Matrix from the previous values\n",
    "print(np.diag(np.diag(x)))\n",
    "\n",
    "#So, after this step, we generated a diagonal matrix based on another matrix using numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetric Matrices\n",
    "- Matrix that is equal to its Transpose\n",
    "- **A = $A^{T}$**\n",
    "- $\\begin{bmatrix} 1 & 2 & 3\\\\ 2 & 3 & 4 \\\\ 3 & 4 & 5 \\end{bmatrix}$\n",
    "- Such matrices exists when the entries are generated by functions that are similar from both sides\n",
    "  - example: if this matrix holds distances between points(i,j) - d(i,j) = d(j,i)\n",
    "  - Usually, Euclidean distances are symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Symmetric Matrices Example\n",
    "a = np.array(([1,2,3],[2,3,4],[3,4,5]))\n",
    "np.allclose(a, a.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another Symmetric Matrices Example\n",
    "a = np.array(np.arange(9).reshape(3,3))\n",
    "np.allclose(a, a.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Unit Vector\n",
    "- Vector with unit norm\n",
    "- $\\left\\lVert x\\right\\rVert _{2} = 1$\n",
    "  - L2 norm\n",
    "  - also known as Euclidean norm; not recommended name\n",
    "  - also known as *magnitude*\n",
    "  - Cartesian distance from origin\n",
    "  - $\\sqrt{\\sum x_{i}^{2}}\\;\\forall\\;_{i}\\;in \\;X$\n",
    "- Unit vector can be obtained by normalizing any vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Normalization\n",
    "- The process of dividing a vector by its magnitude, which produces a unit vector\n",
    "- $\\frac{X}{\\left\\lVert x\\right\\rVert _{2}}$ = unit vector\n",
    "- Dividing the vector by its magnitude gives us the unit vector\n",
    "- Common preprocessing step\n",
    "- Example\n",
    "  - $x = \\begin{bmatrix} 1 & 1 & 1 & 1 \\end{bmatrix}$\n",
    "  - $\\frac{x}{\\sqrt{4}} = \\begin{bmatrix} 1/2 & 1/2 & 1/2 & 1/2 \\end{bmatrix}$\n",
    "  - This vector has magnitude of 1, so it is a unit vector\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting Vector Norm Example\n",
    "from numpy import linalg as LA\n",
    "\n",
    "# Types of supported norms\n",
    "# ord \tnorm for matrices \tnorm for vectors\n",
    "# None \tFrobenius norm \t2-norm\n",
    "# ‘fro’ \tFrobenius norm \t–\n",
    "# ‘nuc’ \tnuclear norm \t–\n",
    "# inf \tmax(sum(abs(x), axis=1)) \tmax(abs(x))\n",
    "# -inf \tmin(sum(abs(x), axis=1)) \tmin(abs(x))\n",
    "# 0 \t– \tsum(x != 0)\n",
    "# 1 \tmax(sum(abs(x), axis=0)) \tas below\n",
    "# -1 \tmin(sum(abs(x), axis=0)) \tas below\n",
    "# 2 \t2-norm (largest sing. value) \tas below\n",
    "# -2 \tsmallest singular value \tas below\n",
    "# other \t– \tsum(abs(x)**ord)**(1./ord)\n",
    "\n",
    "a = np.ones(4, dtype=int)\n",
    "# print(a)\n",
    "LA.norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  0.  1.]\n",
      " [ 0.  1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix Normalization Example\n",
    "# The intuition for normalizing the vectors is that elements within the vector that have large magnitudes may not be more important, \n",
    "# so normalizing them puts all elements roughly in the same scale.\n",
    "# Note, we are using sklearn package here\n",
    "# sudo pip install -U scikit-learn\n",
    "\n",
    "from sklearn import preprocessing\n",
    " \n",
    "# Two samples, with 3 dimensions.\n",
    "# The 2 rows indicate 2 samples, \n",
    "# and the 3 columns indicate 3 features for each sample.\n",
    "X = np.asarray([[-1,0,1],\n",
    "                [0,1,2]], dtype=np.float) # Float is needed.\n",
    " \n",
    "# Before-normalization.\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.70710678  0.          0.70710678]\n",
      " [ 0.          0.4472136   0.89442719]]\n"
     ]
    }
   ],
   "source": [
    "# Symmetric Matrices Example\n",
    "# l2-normalize the samples (rows). \n",
    "X_normalized = preprocessing.normalize(X, norm='l2')\n",
    " \n",
    "# After normalization.\n",
    "print(X_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonality\n",
    "- vector $x$ and vector $y$ are orthogonal to each other if $x^{T}y = 0$\n",
    "- If two vectors are orthogonal and both have a nonzero magnitude, they will be at a 90 degree angle to each other\n",
    "- If two vectors are orthogonal and unit vectors, they are called orthonormal\n",
    "- ![](imgs/Lecture-02/arrowperp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symmetric Matrices Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigen Decomposition\n",
    "- breaking mathematical objects into their constituent parts\n",
    "- mathematical objects can be understood better when they are broken into their constituetional parts\n",
    "  - integers could be decomposed into prime factors\n",
    "  - As 10 = 2 * 5, \n",
    "    - 10 is not divisible by 3\n",
    "    - any integer that is multiple by 10, is also divisible by 5\n",
    "- We can decompose matrices in ways that reveals information about their functional properties that is not immediately obvious from the representation of the matrix as an array of elements\n",
    "- Matrix, can be represented as\n",
    "  - Eigenvectors\n",
    "  - Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigen Vectors and Eigenvalues\n",
    "- Eigenvector of a square matrix $A$ is a nonzero vector $v$ such that multiplication by $A$ alters only the scale of $v$\n",
    "- $A v = \\lambda v$\n",
    "- This is called: Eigenvalue equation\n",
    "- $v$ - the eigenvector\n",
    "- $\\lambda$ - a scalar, the eigenvalue corresponding to $v$\n",
    "- Eigenvector is used to longee or shirnk the matrix\n",
    "- ![](imgs/Lecture-02/eigen.png)\n",
    "- Figure shows the effect of Multiplication of the two orthonormal eigenvectors $^{1}$ and $^{2}$ by the matrix $A$ that lead to the distort of the unit circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
